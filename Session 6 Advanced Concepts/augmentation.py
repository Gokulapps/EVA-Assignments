# -*- coding: utf-8 -*-
"""Augmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JdiytSSisEmULwLr30_UmSZVsRdwxY9z
"""
import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torch.autograd as grad
import matplotlib.pyplot as plt
import numpy as np
import albumentations as A
import warnings
from torch.optim.lr_scheduler import StepLR
from torchvision import datasets, transforms
from torch.utils.data import Dataset, DataLoader
warnings.filterwarnings("ignore")


class Augmentation:
  def __init__(self, images):
    self.images = images.to('cpu').numpy()

  def shiftscalerotate(self):
    augmentedImages = []
    for index in range(self.images.shape[0]):
      transform = A.Compose([A.ShiftScaleRotate(p=0.5)])
      transformed = transform(image=self.images[index])
      augmentedImages.append(transformed['image'])
    return np.stack(augmentedImages, axis=0)

  def hflip(self):
    augmentedImages = []
    for index in range(self.images.shape[0]):
      transform = A.Compose([A.HorizontalFlip(p=0.5)])
      transformed = transform(image=self.images[index])
      augmentedImages.append(transformed['image'])
    return np.stack(augmentedImages, axis=0)

  def cutout(self):
    augmentedImages = []
    for index in range(self.images.shape[0]):
      transform = A.Compose([A.CoarseDropoutV2(max_holes=1, max_height=self.images[index].shape[1]//2, max_width=self.images[index].shape[2]//2, 
                            fill_value=0.5, p=0.5, always_apply=False)])
      transformed = transform(image=self.images[index])
      augmentedImages.append(transformed['image'])
    return np.stack(augmentedImages, axis=0)

  def __call__(self):
    return torch.from_numpy(np.concatenate((self.hflip(), self.shiftscalerotate()), axis=0))
    # return np.concatenate((self.hflip(), self.shiftscalerotate(), self.cutout()), axis=0)