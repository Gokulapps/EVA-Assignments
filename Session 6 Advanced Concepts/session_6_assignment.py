# -*- coding: utf-8 -*-
"""Session 6 Assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tWZ_vRWllZQg0bchGXjaVYTG7Mx6Mi__

Importing Necessary Libraries and Modules
"""

import torch 
import torchvision 
import torch.nn as nn 
import torch.nn.functional as F
import torch.optim as optim 
import torch.autograd as grad
import matplotlib.pyplot as plt
import numpy as np
import warnings
from augmentation import Augmentation
from model_cifar10 import Network 
from train_and_test import test,train
from utils import visualize_images, plot_graph, plot_misclassified_images, get_mean_and_std
from torch.optim.lr_scheduler import StepLR
from torchvision import datasets, transforms
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
from __future__ import print_function
warnings.filterwarnings("ignore")

"""Defining Train and Test Transform for the Dataset"""

# Transformations for Training Images
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, 
                                        transform = transforms.Compose([transforms.ToTensor()]))
testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True,
                                       transform=transforms.Compose([transforms.ToTensor()])) 
# Calculating Mean and Standard Deviation of the Dataset
train_dataset_mean, train_dataset_std = map(tuple, get_mean_and_std(trainset))
test_dataset_mean, test_dataset_std = map(tuple, get_mean_and_std(testset))
# Transformations for Training Images
train_transforms = transforms.Compose([
                                      #  transforms.RandomRotation((-7.0, 7.0), fill=(1,)),
                                      #  transforms.RandomAffine((10.0), fill=1),
                                       transforms.ToTensor(),
                                       transforms.Normalize(train_dataset_mean, train_dataset_std)
                                       ])
# Transformations for Testing Images
test_transforms = transforms.Compose([                                    
                                       transforms.ToTensor(),
                                       transforms.Normalize(test_dataset_mean, test_dataset_std)
                                       ])

"""Mean and Standard Deviation of the Train and Test Dataset"""

print(f'Mean of the Train Dataset = {train_dataset_mean}, Standard Deviation of the Train Dataset = {train_dataset_std}')
print(f'Mean of the Test Dataset = {test_dataset_mean}, Standard Deviation of the Test Dataset = {test_dataset_std}')

"""Loading the Data in Batches through DataLoader """

SEED = 1
cuda = torch.cuda.is_available()
if cuda:
  torch.manual_seed(SEED)
  device = torch.device('cuda')
else:
  device = torch.device('cpu')

trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,
                                          shuffle=True, num_workers=2, pin_memory = True)
testloader = torch.utils.data.DataLoader(testset, batch_size=4,
                                         shuffle=True, num_workers=2, pin_memory = True)

"""Sample Images of the Dataset"""

images, target = next(iter(trainloader))
classes = trainset.classes
visualize_images(images, target, classes)

"""Model Summary"""

model = Network()
print(model.network_architecture())

"""Visualizing Augmented Images """

model = Network()
model.train()
classes = trainset.classes
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
(images, target) = next(iter((trainloader)))
images, target = images.to(device), target.repeat(3).to(device)
augment = Augmentation(images)
augmentedImages = augment()
visualize_images(augmentedImages, target, classes, fig_size=(12, 6))

"""Training the Model 

---


"""

test_losses = []
test_acc = []
incorrect_prediction = []
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model =  Network().to(device)
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
scheduler = StepLR(optimizer, step_size=15, gamma=0.1)
EPOCHS = 40
for epoch in range(1, EPOCHS+1):
    print("EPOCH:", epoch)
    train(model, device, trainloader, optimizer, True)
    scheduler.step()
    test(model, device, testloader, test_losses, test_acc, incorrect_prediction)

"""Plotting Validation Loss and Validation Accuracy"""

plot_graph(test_losses, test_acc)

"""Plotting 10 Misclassified Images of Model"""

classes = trainset.classes
plot_misclassified_images(incorrect_prediction, classes)