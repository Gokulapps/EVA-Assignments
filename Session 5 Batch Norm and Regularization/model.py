# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j5gpxthAs-mj10fCdFOmdZI2a9_9O2Kl
"""

import torch 
import torch.nn as nn 
import torch.nn.functional as F
from torchsummary import summary

class Network(nn.Module):
  def __init__(self, norm = 'BN'):
    super(Network, self).__init__()
    if norm.upper() == 'BN':
      # Convolution Block 1
      self.conv1 = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, bias=False),
                                 nn.BatchNorm2d(8),
                                 nn.ReLU()) # input = 1*28*28, output = 8*26*26, RF = 3 || (1*(3-1)*1)
      self.conv2 = nn.Sequential(nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, bias=False),
                                 nn.BatchNorm2d(16),
                                 nn.ReLU()) # input = 8*26*26, output = 8*24*24, RF = 5 || (3+(3-1)*1)
      self.conv3 = nn.Sequential(nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, bias=False),
                                 nn.Dropout2d(0.05),
                                 nn.BatchNorm2d(16),
                                 nn.ReLU()) # input = 8*24*24, output = 16*22*22, RF = 7 || (5+(3-1)*1)
      # Transition Block
      self.conv4 = nn.Sequential(nn.Conv2d(in_channels=16, out_channels=8, kernel_size=1, bias=False, stride=2),
                                 nn.BatchNorm2d(8),
                                 nn.ReLU()) # input = 16*22*22, output = 8*11*11, RF = 7 || (7+(1-1)*1)
      # Convolution Block 2
      self.conv5 = nn.Sequential(nn.Conv2d(in_channels=8, out_channels=10, kernel_size=3, bias=False),
                                 nn.BatchNorm2d(10),
                                 nn.ReLU()) # input = 8*11*11, output=8*9*9, RF = 11 || (7+(3-1)*2)
      self.conv6 = nn.Sequential(nn.Conv2d(in_channels=10, out_channels=14, kernel_size=3, bias=False),
                                 nn.BatchNorm2d(14), 
                                 nn.ReLU()) # input = 8*9*9, output = 8*7*7, RF = 15 || (11+(3-1)*2)
      self.conv7 = nn.Sequential(nn.Conv2d(in_channels=14, out_channels=16, kernel_size=3, bias=False, padding=1, padding_mode='replicate'),
                                 nn.Dropout2d(0.05),
                                 nn.BatchNorm2d(16), 
                                 nn.ReLU()) # input = 8*7*7, output = 16*7*7, RF = 19 || (17+(5-1)*2)
    elif norm.upper() == 'LN':
      # Convolution Block 1
      self.conv1 = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, bias=False),
                                 nn.GroupNorm(1, 8),
                                 nn.ReLU()) # input = 1*28*28, output = 8*26*26, RF = 3 || (1*(3-1)*1)
      self.conv2 = nn.Sequential(nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, bias=False),
                                 nn.GroupNorm(1, 16),
                                 nn.ReLU()) # input = 8*26*26, output = 16*24*24, RF = 5 || (3+(3-1)*1)
      self.conv3 = nn.Sequential(nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, bias=False),
                                 nn.Dropout2d(0.05),
                                 nn.GroupNorm(1, 16),
                                 nn.ReLU()) # input = 8*24*24, output = 16*22*22, RF = 7 || (5+(3-1)*1)
      # Transition Block
      self.conv4 = nn.Sequential(nn.Conv2d(in_channels=16, out_channels=8, kernel_size=1, bias=False, stride=2),
                                 nn.GroupNorm(1, 8),
                                 nn.ReLU()) # input = 16*22*22, output = 8*11*11, RF = 7 || (7+(1-1)*1)
      # Convolution Block 2
      self.conv5 = nn.Sequential(nn.Conv2d(in_channels=8, out_channels=10, kernel_size=3, bias=False),
                                 nn.GroupNorm(1, 10),
                                 nn.ReLU()) # input = 8*11*11, output=8*9*9, RF = 11 || (7+(3-1)*2)
      self.conv6 = nn.Sequential(nn.Conv2d(in_channels=10, out_channels=12, kernel_size=3, bias=False),
                                 nn.GroupNorm(1, 12), 
                                 nn.ReLU()) # input = 8*9*9, output = 8*7*7, RF = 15 || (11+(3-1)*2)
      self.conv7 = nn.Sequential(nn.Conv2d(in_channels=12, out_channels=16, kernel_size=3, bias=False, padding=1, padding_mode='replicate'),
                                 nn.Dropout2d(0.05),
                                 nn.GroupNorm(1, 16), 
                                 nn.ReLU()) # input = 8*7*7, output = 16*7*7, RF = 19 || (17+(5-1)*2)
    elif norm.upper() == 'GN':
      # Convolution Block 1
      self.conv1 = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, bias=False),
                                 nn.GroupNorm(2, 8),
                                 nn.ReLU()) # input = 1*28*28, output = 8*26*26, RF = 3 || (1*(3-1)*1)
      self.conv2 = nn.Sequential(nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, bias=False),
                                 nn.GroupNorm(2, 16),
                                 nn.ReLU()) # input = 8*26*26, output = 8*24*24, RF = 5 || (3+(3-1)*1)
      self.conv3 = nn.Sequential(nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, bias=False),
                                 nn.Dropout2d(0.05),
                                 nn.GroupNorm(2, 16),
                                 nn.ReLU()) # input = 8*24*24, output = 16*22*22, RF = 7 || (5+(3-1)*1)
      # Transition Block
      self.conv4 = nn.Sequential(nn.Conv2d(in_channels=16, out_channels=8, kernel_size=1, stride=2, bias=False),
                                 nn.GroupNorm(2, 8),
                                 nn.ReLU()) # input = 16*22*22, output = 8*11*11, RF = 7 || (7+(1-1)*1)
      # Convolution Block 2
      self.conv5 = nn.Sequential(nn.Conv2d(in_channels=8, out_channels=10, kernel_size=3, bias=False),
                                 nn.GroupNorm(2, 10),
                                 nn.ReLU()) # input = 8*11*11, output=8*9*9, RF = 11 || (7+(3-1)*2)
      self.conv6 = nn.Sequential(nn.Conv2d(in_channels=10, out_channels=12, kernel_size=3, bias=False),
                                 nn.GroupNorm(2, 12), 
                                 nn.ReLU()) # input = 8*9*9, output = 8*7*7, RF = 15 || (11+(3-1)*2)
      self.conv7 = nn.Sequential(nn.Conv2d(in_channels=12, out_channels=16, kernel_size=3, bias=False, padding=1, padding_mode='replicate'),
                                 nn.Dropout2d(0.05),
                                 nn.GroupNorm(2, 16), 
                                 nn.ReLU()) # input = 8*7*7, output = 16*7*7, RF = 19 || (17+(5-1)*2)

    # Output Block 
    self.gap = nn.AvgPool2d(7) # input = 16*7*7, output = 16*1*1, RF = 31 || (19+(7-1)*2)
    # Flattened Input is given to the Output Layer
    self.output_fc = nn.Linear(in_features=16, out_features=10) # input = 1*16, output = 1*10

  def forward(self, tensor):
    # Input Layer/Block
    x = tensor 
    # Convolution Block 1
    x = self.conv1(x)
    x = self.conv2(x)
    x = self.conv3(x)
    # Transition Block
    x = self.conv4(x)
    # Convolution Block 2
    x = self.conv5(x)
    x = self.conv6(x)
    x = self.conv7(x)
    # Output Block
    x = self.gap(x)
    x = x.reshape(x.shape[0], 16) # Flattening the Input
    x = self.output_fc(x)

    return F.log_softmax(x, dim = 1)

def model_parameters(normtype='BN'):
  use_cuda = torch.cuda.is_available()
  device = torch.device('cuda' if use_cuda else 'cpu')
  sample = Network(normtype).to(device)
  return summary(sample, input_size = (1, 28, 28))